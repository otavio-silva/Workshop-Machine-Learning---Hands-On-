{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop - $\\textit{Hands On}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando para instalar tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando para instalar tensorflow com suporte a GPU (apenas rexecute esta célula se tiver uma GPU com CUDA e cuDNN!!!!)\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para instalar os pacotes necessários\n",
    "!pip install numpy pandas matplotlib seaborn sklearn xgboost keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.logging.set_verbosity(tensorflow.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rodar apenas se estiver rodando GPU localmente e tiver problemas com alocação de memória!!\n",
    "config = tensorflow.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(tensorflow.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import xgboost\n",
    "import seaborn\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from matplotlib import pyplot\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_style(\"darkgrid\")\n",
    "models_list = {}\n",
    "auc_list = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Neste <i>workshop</i> serão feitas várias demostrações de modelos de aprendizado para classificação supervisionada, utilizando algoritmos de aprendizado linear, estatístico, diferentes tipos de <i>ensembles</i> e ao final um exemplo com uma rede neural construída com o <i>Keras</i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura e Análise Dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nossa base de dados é um compilado de informações sobre exoplanetas da NASA (proveniente do [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/index.html)) que possui várias informações sobre planetas confirmados exoplanetas e falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"koi_database.csv\")\n",
    "classes = [\"Confirmados\", \"Falsos Positivos\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linhas:\", df.shape[0])\n",
    "print(\"Colunas:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos eliminar colunas desnecessárias para o aprendizado, e também colunas que enviesam os algoritmos (informações disponíveis após a confirmação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"kepoi_name\", \"kepid\", \"kepler_name\", \"koi_fpflag_nt\", \"koi_score\", \"koi_pdisposition\", \"koi_tce_delivname\", \"koi_teq_err1\", \"koi_teq_err2\", \"koi_fpflag_ss\", \"koi_fpflag_co\", \"koi_fpflag_ec\"], axis=1)\n",
    "df = df[df[\"koi_disposition\"] != \"CANDIDATE\"]\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui aplicamos <i>one-hot encoding</i> na base para determinarmos as classes 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"koi_disposition\"] = df[\"koi_disposition\"].apply(lambda x: 1 if x == \"CONFIRMED\" else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"koi_disposition\"]\n",
    "pyplot.subplots(figsize=(8, 10))\n",
    "seaborn.barplot(data=pandas.DataFrame({\"Confirmados\": y.sum(), \"Falsos Positivos\": y.size - y.sum()}, index=classes)).set_title(\"Classes\", fontsize=20)\n",
    "pyplot.show()\n",
    "print(\"Confirmados:\", y.sum())\n",
    "print(\"Falsos Positivos:\", y.size - y.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aui é feita a normalização <i>z-score</i> em nossos dados para ajudar na perda dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.33, random_state=42)\n",
    "mi = numpy.mean(x_train)\n",
    "sigma = numpy.std(x_train)\n",
    "x_train = (x_train - mi) / sigma\n",
    "x_test = (x_test - mi) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns[1:]:\n",
    "    _, axis = pyplot.subplots(figsize=(20, 8))\n",
    "    seaborn.distplot(df[i][df[\"koi_disposition\"] == 1], bins=256, label=\"Confirmados\")\n",
    "    seaborn.distplot(df[i][df[\"koi_disposition\"] == 0], bins=256, label=\"Falsos Positivos\")\n",
    "    axis.set_title(\"Histograma De Feature: \" + i,fontsize=20)\n",
    "    pyplot.legend(fontsize=15)\n",
    "    pyplot.show()\n",
    "    print(pandas.DataFrame({\"Média\": [numpy.mean(df[i][df[\"koi_disposition\"] == 1]), numpy.mean(df[i][df[\"koi_disposition\"] == 0])],\n",
    "                            \"Variância\": [numpy.var(df[i][df[\"koi_disposition\"] == 1]), numpy.var(df[i][df[\"koi_disposition\"] == 0])]}, index=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(8, 10))\n",
    "seaborn.barplot(data=pandas.DataFrame({\"Confirmados\": y_train.sum(), \"Falsos Positivos\": y_train.size - y_train.sum()}, index=classes)).set_title(\"Classes (Treino e Validação)\")\n",
    "pyplot.show()\n",
    "print(\"Confirmados:\", y_train.sum())\n",
    "print(\"Falsos Positivos:\", y_train.size - y_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(8, 10))\n",
    "seaborn.barplot(data=pandas.DataFrame({\"Confirmados\": y_test.sum(), \"Falsos Positivos\": y_test.size - y_test.sum()}, index=classes)).set_title(\"Classes (Teste)\")\n",
    "pyplot.show()\n",
    "print(\"Confirmados:\", y_test.sum())\n",
    "print(\"Falsos Positivos:\", y_test.size - y_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>K-Fold</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = list(model_selection.KFold(5, shuffle=True).split(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, sets, x, y, p):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for train_set, test_set in sets:\n",
    "        x_train, y_train = x.iloc[train_set], y.iloc[train_set]\n",
    "        x_test, y_test = x.iloc[test_set], y.iloc[test_set]\n",
    "        l = model(x_train, y_train, x_test, y_test, p)\n",
    "        l1.append(l[0])\n",
    "        l2.append(l[1])\n",
    "    return l1, l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_perceptron(x_train, y_train, x_test, y_test, p):\n",
    "    pt = linear_model.Perceptron(penalty=p)\n",
    "    pt.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, pt.predict(x_train)), metrics.accuracy_score(y_test, pt.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1_mean, pt1_var, pt2_mean, pt2_var = [], [], [], []\n",
    "for i in [\"l2\", \"l1\", \"elasticnet\"]:\n",
    "    a1, a2 = cross_validation(linear_perceptron, sets, x_train, y_train, i)\n",
    "    pt1_mean.append(numpy.mean(a1))\n",
    "    pt1_var.append(numpy.var(a1))\n",
    "    pt2_mean.append(numpy.mean(a2))\n",
    "    pt2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame({\"Treino (Média)\": pt1_mean, \"Treino (Variância)\": pt1_var, \"Validação (Média)\": pt2_mean, \"Validação (Variância)\": pt2_var}, index=[\"l2\", \"l1\", \"elasticnet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "ac = metrics.accuracy_score(y_test, pt_y_pred)\n",
    "models_list[\"Perceptron\"] = ac\n",
    "print(\"Accurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, pt_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\")\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, pt_y_pred)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Perceptron\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Naive Bayes</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(x_train, y_train, x_test, y_test, p):\n",
    "    gnv = naive_bayes.GaussianNB()\n",
    "    gnv.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, gnv.predict(x_train)), metrics.accuracy_score(y_test, gnv.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1, g2 = cross_validation(gaussian_naive_bayes, sets, x_train, y_train, None)\n",
    "pandas.DataFrame({\"Média\": [numpy.mean(g1), numpy.mean(g2)], \"Variância\": [numpy.var(g1), numpy.var(g2)]}, index=[\"Treino\", \"Validação\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnv_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "gnv_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, gnv_y_pred)\n",
    "models_list[\"Naive Bayes\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, gnv_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, gnv_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Naive Bayes\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, p):\n",
    "    lr = linear_model.LogisticRegression(solver=p, max_iter=1000, n_jobs=4)\n",
    "    lr.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, lr.predict(x_train)), metrics.accuracy_score(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1_mean, lr1_var, lr2_mean, lr2_var = [], [], [], []\n",
    "for i in [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]:\n",
    "    a1, a2 = cross_validation(logistic_regression, sets, x_train, y_train, i)\n",
    "    lr1_mean.append(numpy.mean(a1))\n",
    "    lr1_var.append(numpy.var(a1))\n",
    "    lr2_mean.append(numpy.mean(a2))\n",
    "    lr2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame({\"Treino (Média)\": lr1_mean, \"Treino (Variância)\": lr1_var, \"Validação (Média)\": lr2_mean, \"Validação (Variância)\": lr2_var}, index=[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "lr_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, lr_y_pred)\n",
    "models_list[\"Regressão Logística\"] = ac\n",
    "print(\"Accurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, lr_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, lr_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Regressão Logística\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore De Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x_train, y_train, x_test, y_test, p):\n",
    "    t = tree.DecisionTreeClassifier(max_depth=p)\n",
    "    t.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, t.predict(x_train)), metrics.accuracy_score(y_test, t.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_mean, t1_var, t2_mean, t2_var = [], [], [], []\n",
    "for i in range(1, 31):\n",
    "    a1, a2 = cross_validation(decision_tree, sets, x_train, y_train, i)\n",
    "    t1_mean.append(numpy.mean(a1))\n",
    "    t1_var.append(numpy.var(a1))\n",
    "    t2_mean.append(numpy.mean(a2))\n",
    "    t2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(14, 8))\n",
    "pyplot.xlabel(\"Profundidade\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 31, 1), t1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 31, 1), t2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(14, 8))\n",
    "pyplot.xlabel(\"Profundidade\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 31, 1), t1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 31, 1), t2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "t_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, t_y_pred)\n",
    "models_list[\"Árvove De Decisão\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, t_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, t_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Árvore De Decisão\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Support Vector Machine</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machines(x_train, y_train, x_test, y_test, p):\n",
    "    svm_ = svm.SVC(gamma=\"scale\", kernel=p)\n",
    "    svm_.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, svm_.predict(x_train)), metrics.accuracy_score(y_test, svm_.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_mean, s1_var, s2_mean, s2_var = [], [], [], []\n",
    "for i in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "    a1, a2 = cross_validation(support_vector_machines, sets, x_train, y_train, i)\n",
    "    s1_mean.append(numpy.mean(a1))\n",
    "    s1_var.append(numpy.var(a1))\n",
    "    s2_mean.append(numpy.mean(a2))\n",
    "    s2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame({\"Treino (Média)\": s1_mean, \"Treino (Variância)\": s1_var, \"Validação (Média)\": s2_mean, \"Validação (Variância)\": s2_var}, index=[\"Linear\", \"Sigmóide\", \"Polinomial\", \"RBF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo! ATENÇÃO: quando criar o modelo do SVM, você precisa usar o parâmetro \"probability=True\" se não, não vai funcionar!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "svm_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, svm_y_pred)\n",
    "models_list[\"SVM\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, svm_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, )\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"SVM\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>k-Nearest Neighbours</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(x_train, y_train, x_test, y_test, p):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=p, n_jobs=4)\n",
    "    knn.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, knn.predict(x_train)), metrics.accuracy_score(y_test, knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1_mean, k1_var, k2_mean, k2_var = [], [], [], []\n",
    "for i in range(1, 51):\n",
    "    a1, a2 = cross_validation(k_nearest_neighbours, sets, x_train, y_train, i)\n",
    "    k1_mean.append(numpy.mean(a1))\n",
    "    k1_var.append(numpy.var(a1))\n",
    "    k2_mean.append(numpy.mean(a2))\n",
    "    k2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Vizinhos\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), k1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), k2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Vizinhos\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), k1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), k2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "knn_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, knn_y_pred)\n",
    "models_list[\"k-NN\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, knn_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, knn_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"k-NN\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Adaboost</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(x_train, y_train, x_test, y_test, p):\n",
    "    ab = ensemble.AdaBoostClassifier(n_estimators=p)\n",
    "    ab.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, ab.predict(x_train)), metrics.accuracy_score(y_test, ab.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab1_mean, ab1_var, ab2_mean, ab2_var = [], [], [], []\n",
    "for i in range(1, 51):\n",
    "    a1, a2 = cross_validation(adaboost, sets, x_train, y_train, i)\n",
    "    ab1_mean.append(numpy.mean(a1))\n",
    "    ab1_var.append(numpy.var(a1))\n",
    "    ab2_mean.append(numpy.mean(a2))\n",
    "    ab2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), ab1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), ab2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), ab1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), ab2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "ab_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)\n",
    "ac = metrics.accuracy_score(y_test, ab_y_pred)\n",
    "models_list[\"Adaboost\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, ab_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, ab_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Adaboost\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Bagging</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(x_train, y_train, x_test, y_test, p):\n",
    "    bgg = ensemble.BaggingClassifier(n_jobs=4, n_estimators=p)\n",
    "    bgg.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, bgg.predict(x_train)), metrics.accuracy_score(y_test, bgg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgg1_mean, bgg1_var, bgg2_mean, bgg2_var = [], [], [], []\n",
    "for i in range(1, 51):\n",
    "    a1, a2 = cross_validation(bagging, sets, x_train, y_train, i)\n",
    "    bgg1_mean.append(numpy.mean(a1))\n",
    "    bgg1_var.append(numpy.var(a1))\n",
    "    bgg2_mean.append(numpy.mean(a2))\n",
    "    bgg2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), bgg1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), bgg2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), bgg1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), bgg2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgg_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "bgg_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, bgg_y_pred)\n",
    "models_list[\"Bagging\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, bgg_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, bgg_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "print(\"AUC Score:\", metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Random Forest</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, y_train, x_test, y_test, p):\n",
    "    rf = ensemble.RandomForestClassifier(max_depth=5, n_estimators=p)\n",
    "    rf.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, rf.predict(x_train)), metrics.accuracy_score(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1_mean, rf1_var, rf2_mean, rf2_var = [], [], [], []\n",
    "for i in range(1, 51):\n",
    "    a1, a2 = cross_validation(random_forest, sets, x_train, y_train, i)\n",
    "    rf1_mean.append(numpy.mean(a1))\n",
    "    rf1_var.append(numpy.var(a1))\n",
    "    rf2_mean.append(numpy.mean(a2))\n",
    "    rf2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), rf1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), rf2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), rf1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), rf2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "rf_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, rf_y_pred)\n",
    "models_list[\"Random Forest\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, rf_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, rf_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Gradient Tree Boosting</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_tree_boosting(x_train, y_train, x_test, y_test, p):\n",
    "    gtb = ensemble.GradientBoostingClassifier(n_estimators=p)\n",
    "    gtb.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, gtb.predict(x_train)), metrics.accuracy_score(y_test, gtb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtb1_mean, gtb1_var, gtb2_mean, gtb2_var = [], [], [], []\n",
    "for i in range(1, 51):\n",
    "    a1, a2 = cross_validation(gradient_tree_boosting, sets, x_train, y_train, i)\n",
    "    gtb1_mean.append(numpy.mean(a1))\n",
    "    gtb1_var.append(numpy.var(a1))\n",
    "    gtb2_mean.append(numpy.mean(a2))\n",
    "    gtb2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), gtb1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), gtb2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), gtb1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), gtb2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtb_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "gbt_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, gtb_y_pred)\n",
    "models_list[\"Gradient Tree Boosting\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, gtb_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, gbt_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Gradient Tree Boosting\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>XGBoost</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_tree(x_train, y_train, x_test, y_test, p):\n",
    "    xgb = xgboost.sklearn.XGBClassifier(n_jobs=4, n_estimators=p)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    return (metrics.accuracy_score(y_train, xgb.predict(x_train)), metrics.accuracy_score(y_test, xgb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1_mean, xgb1_var, xgb2_mean, xgb2_var = [], [], [], []\n",
    "for i in range(1, 51):\n",
    "    a1, a2 = cross_validation(xgb_tree, sets, x_train, y_train, i)\n",
    "    xgb1_mean.append(numpy.mean(a1))\n",
    "    xgb1_var.append(numpy.var(a1))\n",
    "    xgb2_mean.append(numpy.mean(a2))\n",
    "    xgb2_var.append(numpy.var(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Acurácia (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), xgb1_mean, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), xgb2_mean, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(12, 8))\n",
    "pyplot.xlabel(\"Número De Estimadores\", fontsize=15)\n",
    "pyplot.ylabel(\"Variância (Média)\", fontsize=15)\n",
    "pyplot.plot(numpy.arange(1, 51, 1), xgb1_var, \"r-\", label=\"Treino\")\n",
    "pyplot.plot(numpy.arange(1, 51, 1), xgb2_var, \"b-\", label=\"Validação\")\n",
    "pyplot.legend(fontsize=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira aqui o seu código selecionando o hiperparâmetro ótimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_pred = NOME_DO_SEU_MODELO_AQUI.predict(x_test)\n",
    "xgb_y_pred_proba = NOME_DO_SEU_MODELO_AQUI.predict_proba(x_test)[:, 1]\n",
    "ac = metrics.accuracy_score(y_test, xgb_y_pred)\n",
    "models_list[\"XGBoost\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, xgb_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, xgb_y_pred_proba)\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"XGBoost\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Multicamadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network():\n",
    "    net = models.Sequential()\n",
    "    #Construa sua própria rede, use sua criatividade! Funções de ativação: \"relu\", \"softsign\", \"tanh\", \"sigmoid\", \"softmax\", \"elu\", \"selu\", \"softplus\", \"exponential\", \"linear\"\n",
    "    #DICA 1: Use camadas com tamanho de potências de 2!\n",
    "    #DICA 2: funções de ativação como \"relu\", \"linear\" e \"softsign\" são mais baratas computacionalmente!\n",
    "    \n",
    "    net.add(layers.Dense(1, activation=\"sigmoid\", name=\"Output\"))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(x_train, y_train, x_test, y_test, p):\n",
    "    net = create_neural_network()\n",
    "    net.compile(optimizer=optimizers.Adagrad(lr=0.0253), loss=\"binary_crossentropy\")\n",
    "    net.fit(x_train.values, y_train.values, epochs=50, batch_size=32, verbose=0)\n",
    "    return (metrics.accuracy_score(y_train, net.predict_classes(x_train.values)), metrics.accuracy_score(y_test, net.predict_classes(x_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, a2 = cross_validation(neural_network, sets, x_train, y_train, None)\n",
    "pandas.DataFrame({\"Média\": [numpy.mean(a1), numpy.mean(a2)], \"Variância\": [numpy.var(a1), numpy.var(a2)]}, index=[\"Treino\", \"Validação\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_neural_network()\n",
    "net.compile(optimizer=optimizers.Adagrad(lr=0.0253), loss=\"binary_crossentropy\")\n",
    "net.fit(x_train.values, y_train.values, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_y_pred = net.predict_classes(x_test.values)\n",
    "ac = metrics.accuracy_score(y_test, net_y_pred)\n",
    "models_list[\"Rede Neural Multicamadas\"] = ac\n",
    "print(\"Acurácia:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, net_y_pred)\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "seaborn.set(font_scale=1.2)\n",
    "seaborn.heatmap(pandas.DataFrame(cm, index=classes, columns=classes), annot=False, cmap=\"BuPu\").set_title(\"Matriz De Confusão\", fontsize=20)\n",
    "pyplot.xlabel(\"Predito\", fontsize=18)\n",
    "pyplot.ylabel(\"Real\", fontsize=18)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_test, net.predict(x_test))\n",
    "pyplot.subplots(figsize=(12, 10))\n",
    "pyplot.plot([0,1], [0, 1], \"k--\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.xlabel(\"Recall\")\n",
    "pyplot.ylabel(\"Precision\")\n",
    "pyplot.title(\"ROC Curve\")\n",
    "pyplot.show()\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc_list[\"Rede Neural Multicamadas\"] = auc\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação Entre Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sorted(models_list.items(), key=lambda x: x[1])\n",
    "zlist = list(zip(*z))\n",
    "pyplot.subplots(figsize=(16, 8))\n",
    "pyplot.barh(zlist[0], zlist[1])\n",
    "pyplot.title(\"Acurácia (Teste)\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sorted(auc_list.items(), key=lambda x: x[1])\n",
    "zlist = list(zip(*z))\n",
    "pyplot.subplots(figsize=(16, 8))\n",
    "pyplot.barh(zlist[0], zlist[1])\n",
    "pyplot.title(\"AUC (Teste)\")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
